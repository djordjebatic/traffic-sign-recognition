from sklearn.metrics import accuracy_score
from statistics import mean
import numpy as np
import sys
import os
import pandas as pd
import glob


def bb_intersection_over_union(boxA, boxB):
    # determine the (x, y)-coordinates of the intersection rectangle
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[2], boxB[2])
    yB = min(boxA[3], boxB[3])
    # compute the area of intersection rectangle
    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)
    # compute the area of both the prediction and ground-truth
    # rectangles
    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)
    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)

    # compute the intersection over union by taking the intersection
    # area and dividing it by the sum of prediction + ground-truth
    # areas - the interesection area
    iou = interArea / float(boxAArea + boxBArea - interArea)

    # return the intersection over union value
    return iou

# ------------------------------------------------------------------
# Ovaj fajl ne menjati, da bi automatsko ocenjivanje bilo moguce
if len(sys.argv) > 1:
    VALIDATION_DATASET_PATH = sys.argv[1]
else:
    VALIDATION_DATASET_PATH = '.' + os.path.sep + 'dataset' + os.path.sep + 'validation' + os.path.sep
# ------------------------------------------------------------------
RESULTS_PATH = './result.csv'
labeled_samples = dict()
validation_results = pd.read_csv(VALIDATION_DATASET_PATH + 'annotations.csv', sep=";")

# read results file generated by the main.py
results_df = pd.read_csv(RESULTS_PATH, sep=";").sort_values(by=['image_name'])
classification_true_labels = []
classification_predicted_labels = []
iou_all = []

for image_path in glob.glob(VALIDATION_DATASET_PATH + "*.jpg"):
    image_directory, image_name = os.path.split(image_path)
    expected_results = validation_results[validation_results['image_name'] == image_name]
    predicted_results = results_df[results_df['image_name'] == image_name]

    image_iou_matrix = []
    ground_truth_labels = []
    predicted_labels = []

    # map detected and true values
    for truth_row in expected_results.iterrows():
        truth_row = truth_row[1]
        bbox_true = truth_row['x_min'], truth_row['y_min'], truth_row['x_max'], truth_row['y_max']
        sign_true = truth_row['sign_type']
        ground_truth_labels.append(sign_true)

        # find overlap of ground-truth sign with predicted signs
        overlaps = []
        predicted_labels_temp = []

        for predicted_row in predicted_results.iterrows():
            predicted_row = predicted_row[1]
            bbox_temp_predicted = predicted_row['x_min'], predicted_row['y_min'], predicted_row['x_max'], predicted_row['y_max']
            sign_temp_predicted = predicted_row['sign_type']
            overlaps.append(bb_intersection_over_union(bbox_true, bbox_temp_predicted))
            predicted_labels_temp.append(sign_temp_predicted)

        if not predicted_labels:
            predicted_labels = predicted_labels_temp
        image_iou_matrix.append(overlaps)

    image_iou_matrix = np.matrix(image_iou_matrix)
    image_iou = []

    # iteratively find maximum overlaps until matrix is empty or zero matrix
    while image_iou_matrix.size > 0:
        ground_truth_row_index = np.argmax(np.max(image_iou_matrix, axis=1))
        max_value = np.max(image_iou_matrix[ground_truth_row_index, :])
        predicted_column_index = np.argmax(image_iou_matrix[ground_truth_row_index, :])
        # remove processed row (ground truth row)
        image_iou_matrix = np.delete(image_iou_matrix, ground_truth_row_index, axis=0)
        # remove processed column (predicted sign candidate)
        if image_iou_matrix.size > 0:
            image_iou_matrix = np.delete(image_iou_matrix, predicted_column_index, axis=1)
        image_iou.append(max_value)

        # add labels for classification
        classification_true_labels.append(ground_truth_labels[ground_truth_row_index])
        del ground_truth_labels[ground_truth_row_index]
        classification_predicted_labels.append(predicted_labels[predicted_column_index])
        del predicted_labels[predicted_column_index]

    # non-detected ground truth elements should be added automatically to the results
    for ground_truth_label in ground_truth_labels:
        classification_true_labels.append(ground_truth_label)
        classification_predicted_labels.append("DRUGI")

    # false positives should be added to the result too
    image_iou += [0] * (len(ground_truth_labels) + len(predicted_labels))
    if len(image_iou) > 0:
        iou_all.append(sum(image_iou)/len(image_iou))

percentage = accuracy_score(classification_true_labels, classification_predicted_labels) * 100
mean_iou = mean(iou_all) * 100
print((percentage + mean_iou)/2)
